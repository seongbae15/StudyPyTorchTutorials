{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_id': 'n02124075', 'class_name': 'Egyptian_cat'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\"class_id\": \"n02124075\", \"class_name\": \"Egyptian_cat\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Web Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/\")\n",
    "def hello():\n",
    "    return \"Hello World!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from flask import Flask, jsonify\n",
    "# app = Flask(__name__)\n",
    "\n",
    "# @app.route(\"/predict\", methods=[\"POST\"])\n",
    "# def predict():\n",
    "#     return jsonify({\"class_id\": \"IMAGE_NET_XXX\", \"class_name\": \"Cat\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "def transform_image(image_bytes):\n",
    "    my_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                        transforms.CenterCrop(224),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "    image = Image.open(io.BytesIO(image_bytes))\n",
    "    return my_transforms(image).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.4508,  0.4166,  0.3994,  ..., -1.3473, -1.3302, -1.3473],\n",
      "          [ 0.5364,  0.4851,  0.4508,  ..., -1.2959, -1.3130, -1.3302],\n",
      "          [ 0.7077,  0.6392,  0.6049,  ..., -1.2959, -1.3302, -1.3644],\n",
      "          ...,\n",
      "          [ 1.3755,  1.3927,  1.4098,  ...,  1.1700,  1.3584,  1.6667],\n",
      "          [ 1.8893,  1.7694,  1.4440,  ...,  1.2899,  1.4783,  1.5468],\n",
      "          [ 1.6324,  1.8379,  1.8379,  ...,  1.4783,  1.7352,  1.4612]],\n",
      "\n",
      "         [[ 0.5728,  0.5378,  0.5203,  ..., -1.3704, -1.3529, -1.3529],\n",
      "          [ 0.6604,  0.6078,  0.5728,  ..., -1.3004, -1.3179, -1.3354],\n",
      "          [ 0.8529,  0.7654,  0.7304,  ..., -1.3004, -1.3354, -1.3704],\n",
      "          ...,\n",
      "          [ 1.4657,  1.4657,  1.4832,  ...,  1.3256,  1.5357,  1.8508],\n",
      "          [ 2.0084,  1.8683,  1.5182,  ...,  1.4657,  1.6583,  1.7283],\n",
      "          [ 1.7458,  1.9384,  1.9209,  ...,  1.6583,  1.9209,  1.6408]],\n",
      "\n",
      "         [[ 0.7228,  0.6879,  0.6531,  ..., -1.6476, -1.6302, -1.6476],\n",
      "          [ 0.8099,  0.7576,  0.7228,  ..., -1.6476, -1.6476, -1.6650],\n",
      "          [ 1.0017,  0.9145,  0.8797,  ..., -1.6476, -1.6650, -1.6999],\n",
      "          ...,\n",
      "          [ 1.6291,  1.6291,  1.6465,  ...,  1.6291,  1.8208,  2.1346],\n",
      "          [ 2.1868,  2.0300,  1.6814,  ...,  1.7685,  1.9428,  2.0125],\n",
      "          [ 1.9254,  2.0997,  2.0823,  ...,  1.9428,  2.2043,  1.9080]]]])\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/samples/sample_file.jpeg\", \"rb\") as f:\n",
    "    image_bytes = f.read()\n",
    "    tensor = transform_image(image_bytes=image_bytes)\n",
    "    print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SB15\\miniconda3\\envs\\aiWs\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\SB15\\miniconda3\\envs\\aiWs\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "model = models.densenet121(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "def get_prediction(image_bytes):\n",
    "    tensor = transform_image(image_bytes=image_bytes)\n",
    "    outputs = model.forward(tensor)\n",
    "    _, y_hat = outputs.max(1)\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "imagenet_class_index = json.load(open(\"../data/imagenet_class_index.json\"))\n",
    "\n",
    "def get_prediction(image_bytes):\n",
    "    tensor = transform_image(image_bytes=image_bytes)\n",
    "    outputs = model.forward(tensor)\n",
    "    _, y_hat = outputs.max(1)\n",
    "    predicted_idx = str(y_hat.item())\n",
    "    return imagenet_class_index[predicted_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n02124075', 'Egyptian_cat']\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/samples/sample_file.jpeg\", 'rb') as f:\n",
    "    image_bytes = f.read()\n",
    "    print(get_prediction(image_bytes=image_bytes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating the mode in out API Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from flask import request, jsonify\n",
    "\n",
    "# @app.route('/predict', methods=['POST'])\n",
    "# def predict():\n",
    "#     if request.method == 'POST':\n",
    "#         # we will get the file from the request\n",
    "#         file = request.files['file']\n",
    "#         # convert that to bytes\n",
    "#         img_bytes = file.read()\n",
    "#         class_id, class_name = get_prediction(image_bytes=img_bytes)\n",
    "#         return jsonify({'class_id': class_id, 'class_name': class_name})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "\n",
    "from torchvision import models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from flask import Flask, jsonify, request\n",
    "\n",
    "app = Flask(__name__)\n",
    "imagenet_class_index = json.load(open(\"../data/imagenet_class_index.json\"))\n",
    "model = models.densenet121(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "def transform_image(image_bytes):\n",
    "    my_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                        transforms.CenterCrop(224),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "    image = Image.open(io.BytesIO(image_bytes))\n",
    "    return my_transforms(image).unsqueeze(0)\n",
    "\n",
    "def get_prediction(image_bytes):\n",
    "    tensor = transform_image(image_bytes=image_bytes)\n",
    "    outputs = model.forward(tensor)\n",
    "    _, y_hat = outputs.max(1)\n",
    "    predicted_idx = str(y_hat.item())\n",
    "    return imagenet_class_index[predicted_idx]\n",
    "\n",
    "@app.route(\"/\")\n",
    "def hello():\n",
    "    return \"Hello World!\"\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    if request.method == 'POST':\n",
    "        file = request.files['file']\n",
    "        img_bytes = file.read()\n",
    "        class_id, class_name = get_prediction(image_bytes=img_bytes)\n",
    "        return jsonify({'class_id': class_id, 'class_name': class_name})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [05/Dec/2022 10:14:21] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [05/Dec/2022 10:15:30] \"GET /predict HTTP/1.1\" 405 -\n",
      "127.0.0.1 - - [05/Dec/2022 10:15:46] \"GET /predict=%22http://localhost:5000/predict%22,%20files=%7B%22file%22:%20open(%22../data/samples/sample_file.jpeg%22,'rb')%7D HTTP/1.1\" 404 -\n"
     ]
    }
   ],
   "source": [
    "app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "# resp = requests.post(\"http://localhost:5000/predict\",\n",
    "#                      files={\"file\": open(\"../data/samples/sample_file.jpeg\",'rb')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('aiWs')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "764ba4b8d6f2362b477200584944158c9736904205cbc7cf7caf94c24ea1b1a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
